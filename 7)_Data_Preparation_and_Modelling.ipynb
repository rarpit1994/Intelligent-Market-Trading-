{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7) Data Preparation and Modelling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "umHWZlTBWoKS"
      },
      "source": [
        "pip install prince"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfkg6aNK_FPp"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import prince\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "from itertools import cycle\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from itertools import product\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier # Gradient Boosting algo\n",
        "from sklearn.ensemble import AdaBoostClassifier # adaboost classifie"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9hmRWgIhY3a"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqK-6ABN_RVX"
      },
      "source": [
        "embeddings_df = pd.read_csv('/content/drive/MyDrive/BERT + STOCK /title_embeddings.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp7n_mpB_im0"
      },
      "source": [
        "fin_data = pd.read_csv('/content/drive/MyDrive/BERT + STOCK /Label_data_march_02 (1).csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj2I7gMoDvzc",
        "outputId": "a6fbd9ea-5b72-4610-b53c-0829d02cde13"
      },
      "source": [
        "fin_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50416, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWKLFrhoD3mw",
        "outputId": "c59d60bd-5dc8-4885-c5d6-fead963ae389"
      },
      "source": [
        "fin_data.Label.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Hold', 'Bullish', 'Bearish'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "iBdtNWTQ_sCq",
        "outputId": "cde1db3d-b638-4a49-d0f5-96363da9a470"
      },
      "source": [
        "fin_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-10-08</td>\n",
              "      <td>Microsoft Is Bringing Xbox Game Pass to iOS, b...</td>\n",
              "      <td>114.97</td>\n",
              "      <td>116.4</td>\n",
              "      <td>114.5901</td>\n",
              "      <td>116.25</td>\n",
              "      <td>Hold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-10-08</td>\n",
              "      <td>US STOCKS-S&amp;P 500, Dow track second straight w...</td>\n",
              "      <td>114.97</td>\n",
              "      <td>116.4</td>\n",
              "      <td>114.5901</td>\n",
              "      <td>116.25</td>\n",
              "      <td>Hold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-10-08</td>\n",
              "      <td>RPT-U.S. explores restrictions on Ant Group, T...</td>\n",
              "      <td>114.97</td>\n",
              "      <td>116.4</td>\n",
              "      <td>114.5901</td>\n",
              "      <td>116.25</td>\n",
              "      <td>Hold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-10-09</td>\n",
              "      <td>Microsoft Takes Shots at Apple in New App Stor...</td>\n",
              "      <td>116.97</td>\n",
              "      <td>117.0</td>\n",
              "      <td>114.9200</td>\n",
              "      <td>115.28</td>\n",
              "      <td>Hold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-10-09</td>\n",
              "      <td>Pre-Market Most Active for Oct 9, 2020 :  MVIS...</td>\n",
              "      <td>116.97</td>\n",
              "      <td>117.0</td>\n",
              "      <td>114.9200</td>\n",
              "      <td>115.28</td>\n",
              "      <td>Hold</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date                                              title  ...    open  Label\n",
              "0  2020-10-08  Microsoft Is Bringing Xbox Game Pass to iOS, b...  ...  116.25   Hold\n",
              "1  2020-10-08  US STOCKS-S&P 500, Dow track second straight w...  ...  116.25   Hold\n",
              "2  2020-10-08  RPT-U.S. explores restrictions on Ant Group, T...  ...  116.25   Hold\n",
              "3  2020-10-09  Microsoft Takes Shots at Apple in New App Stor...  ...  115.28   Hold\n",
              "4  2020-10-09  Pre-Market Most Active for Oct 9, 2020 :  MVIS...  ...  115.28   Hold\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6h11zfdg911"
      },
      "source": [
        "fin_data = fin_data[['date', 'title', 'close', 'high', 'low', 'open','Label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9W6wymkThCst",
        "outputId": "e31b8a72-a790-4a07-98ad-034acbf376c1"
      },
      "source": [
        "fin_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-10-08</td>\n",
              "      <td>Microsoft Is Bringing Xbox Game Pass to iOS, b...</td>\n",
              "      <td>114.97</td>\n",
              "      <td>116.4</td>\n",
              "      <td>114.5901</td>\n",
              "      <td>116.25</td>\n",
              "      <td>Hold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-10-08</td>\n",
              "      <td>US STOCKS-S&amp;P 500, Dow track second straight w...</td>\n",
              "      <td>114.97</td>\n",
              "      <td>116.4</td>\n",
              "      <td>114.5901</td>\n",
              "      <td>116.25</td>\n",
              "      <td>Hold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-10-08</td>\n",
              "      <td>RPT-U.S. explores restrictions on Ant Group, T...</td>\n",
              "      <td>114.97</td>\n",
              "      <td>116.4</td>\n",
              "      <td>114.5901</td>\n",
              "      <td>116.25</td>\n",
              "      <td>Hold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-10-09</td>\n",
              "      <td>Microsoft Takes Shots at Apple in New App Stor...</td>\n",
              "      <td>116.97</td>\n",
              "      <td>117.0</td>\n",
              "      <td>114.9200</td>\n",
              "      <td>115.28</td>\n",
              "      <td>Hold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-10-09</td>\n",
              "      <td>Pre-Market Most Active for Oct 9, 2020 :  MVIS...</td>\n",
              "      <td>116.97</td>\n",
              "      <td>117.0</td>\n",
              "      <td>114.9200</td>\n",
              "      <td>115.28</td>\n",
              "      <td>Hold</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date                                              title  ...    open  Label\n",
              "0  2020-10-08  Microsoft Is Bringing Xbox Game Pass to iOS, b...  ...  116.25   Hold\n",
              "1  2020-10-08  US STOCKS-S&P 500, Dow track second straight w...  ...  116.25   Hold\n",
              "2  2020-10-08  RPT-U.S. explores restrictions on Ant Group, T...  ...  116.25   Hold\n",
              "3  2020-10-09  Microsoft Takes Shots at Apple in New App Stor...  ...  115.28   Hold\n",
              "4  2020-10-09  Pre-Market Most Active for Oct 9, 2020 :  MVIS...  ...  115.28   Hold\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfJEhjcYhEIj"
      },
      "source": [
        "merged = pd.concat([fin_data, embeddings_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oF_cCDsbp0w",
        "outputId": "8ad4ec0c-7ed2-45ed-85a3-eda6140d44bd"
      },
      "source": [
        "merged.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50416, 775)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNn9h9cEgdqa"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/BERT + STOCK /Fine-tuned Models/apple_training_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "7wp2QTTBHGYG",
        "outputId": "d2a07345-ad54-4c88-c38d-414afcbb3aed"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>728</th>\n",
              "      <th>729</th>\n",
              "      <th>730</th>\n",
              "      <th>731</th>\n",
              "      <th>732</th>\n",
              "      <th>733</th>\n",
              "      <th>734</th>\n",
              "      <th>735</th>\n",
              "      <th>736</th>\n",
              "      <th>737</th>\n",
              "      <th>738</th>\n",
              "      <th>739</th>\n",
              "      <th>740</th>\n",
              "      <th>741</th>\n",
              "      <th>742</th>\n",
              "      <th>743</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hold</td>\n",
              "      <td>0.037546</td>\n",
              "      <td>-0.051923</td>\n",
              "      <td>0.344174</td>\n",
              "      <td>0.043786</td>\n",
              "      <td>-0.123420</td>\n",
              "      <td>-1.090308</td>\n",
              "      <td>-1.268697</td>\n",
              "      <td>0.672538</td>\n",
              "      <td>0.261593</td>\n",
              "      <td>-0.239256</td>\n",
              "      <td>0.420332</td>\n",
              "      <td>1.389317</td>\n",
              "      <td>0.894054</td>\n",
              "      <td>0.116467</td>\n",
              "      <td>0.473175</td>\n",
              "      <td>0.059027</td>\n",
              "      <td>0.248561</td>\n",
              "      <td>-0.619632</td>\n",
              "      <td>0.750312</td>\n",
              "      <td>-0.677750</td>\n",
              "      <td>-0.648951</td>\n",
              "      <td>-1.062019</td>\n",
              "      <td>0.045358</td>\n",
              "      <td>-0.412662</td>\n",
              "      <td>0.160938</td>\n",
              "      <td>-0.308168</td>\n",
              "      <td>-0.249423</td>\n",
              "      <td>-0.734509</td>\n",
              "      <td>-0.811776</td>\n",
              "      <td>0.283796</td>\n",
              "      <td>-0.570970</td>\n",
              "      <td>0.674950</td>\n",
              "      <td>-1.048993</td>\n",
              "      <td>-0.043500</td>\n",
              "      <td>-0.027299</td>\n",
              "      <td>1.132384</td>\n",
              "      <td>1.370240</td>\n",
              "      <td>0.579172</td>\n",
              "      <td>-0.065549</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.301647</td>\n",
              "      <td>-0.565768</td>\n",
              "      <td>1.215243</td>\n",
              "      <td>-0.266465</td>\n",
              "      <td>0.064002</td>\n",
              "      <td>0.508505</td>\n",
              "      <td>-0.251068</td>\n",
              "      <td>0.482107</td>\n",
              "      <td>-0.099638</td>\n",
              "      <td>-0.738906</td>\n",
              "      <td>-0.377724</td>\n",
              "      <td>-0.545664</td>\n",
              "      <td>-0.245191</td>\n",
              "      <td>-0.336827</td>\n",
              "      <td>-0.532866</td>\n",
              "      <td>-1.175896</td>\n",
              "      <td>0.119630</td>\n",
              "      <td>0.475462</td>\n",
              "      <td>-0.195247</td>\n",
              "      <td>-0.035003</td>\n",
              "      <td>0.125132</td>\n",
              "      <td>-0.148954</td>\n",
              "      <td>0.543559</td>\n",
              "      <td>-1.735318</td>\n",
              "      <td>0.275952</td>\n",
              "      <td>0.562077</td>\n",
              "      <td>-0.455644</td>\n",
              "      <td>0.982017</td>\n",
              "      <td>-0.320485</td>\n",
              "      <td>0.530403</td>\n",
              "      <td>-0.196557</td>\n",
              "      <td>-0.799603</td>\n",
              "      <td>-0.627972</td>\n",
              "      <td>-2.115531</td>\n",
              "      <td>0.386281</td>\n",
              "      <td>-0.319896</td>\n",
              "      <td>-0.325062</td>\n",
              "      <td>0.461889</td>\n",
              "      <td>-0.209296</td>\n",
              "      <td>-0.394507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hold</td>\n",
              "      <td>-0.093125</td>\n",
              "      <td>1.055027</td>\n",
              "      <td>-0.438218</td>\n",
              "      <td>-0.322597</td>\n",
              "      <td>0.738876</td>\n",
              "      <td>-0.002521</td>\n",
              "      <td>0.046680</td>\n",
              "      <td>0.686471</td>\n",
              "      <td>-0.388073</td>\n",
              "      <td>0.309424</td>\n",
              "      <td>0.174271</td>\n",
              "      <td>-0.162449</td>\n",
              "      <td>0.315963</td>\n",
              "      <td>0.448883</td>\n",
              "      <td>-0.393337</td>\n",
              "      <td>-0.002808</td>\n",
              "      <td>-0.295760</td>\n",
              "      <td>0.517465</td>\n",
              "      <td>-0.033798</td>\n",
              "      <td>-0.506839</td>\n",
              "      <td>-0.124960</td>\n",
              "      <td>-1.150620</td>\n",
              "      <td>0.446355</td>\n",
              "      <td>0.762440</td>\n",
              "      <td>1.170262</td>\n",
              "      <td>0.480147</td>\n",
              "      <td>-0.559297</td>\n",
              "      <td>-0.357340</td>\n",
              "      <td>-1.020051</td>\n",
              "      <td>0.047867</td>\n",
              "      <td>-0.734048</td>\n",
              "      <td>0.584359</td>\n",
              "      <td>-0.519498</td>\n",
              "      <td>-0.336999</td>\n",
              "      <td>-0.375883</td>\n",
              "      <td>0.490111</td>\n",
              "      <td>-1.139295</td>\n",
              "      <td>-0.970945</td>\n",
              "      <td>-0.585479</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.945933</td>\n",
              "      <td>0.086706</td>\n",
              "      <td>-0.556696</td>\n",
              "      <td>-0.917997</td>\n",
              "      <td>1.075052</td>\n",
              "      <td>0.546898</td>\n",
              "      <td>0.858346</td>\n",
              "      <td>0.005431</td>\n",
              "      <td>0.477956</td>\n",
              "      <td>-0.008171</td>\n",
              "      <td>-0.506317</td>\n",
              "      <td>-1.336613</td>\n",
              "      <td>-0.527256</td>\n",
              "      <td>0.504620</td>\n",
              "      <td>-0.184575</td>\n",
              "      <td>-0.347946</td>\n",
              "      <td>0.198779</td>\n",
              "      <td>0.450703</td>\n",
              "      <td>-0.745462</td>\n",
              "      <td>-0.200957</td>\n",
              "      <td>-0.612498</td>\n",
              "      <td>-0.027740</td>\n",
              "      <td>-0.026578</td>\n",
              "      <td>-1.644605</td>\n",
              "      <td>1.078867</td>\n",
              "      <td>0.613731</td>\n",
              "      <td>-0.465032</td>\n",
              "      <td>0.498639</td>\n",
              "      <td>0.184688</td>\n",
              "      <td>-1.173489</td>\n",
              "      <td>-0.217742</td>\n",
              "      <td>-0.558083</td>\n",
              "      <td>-0.721577</td>\n",
              "      <td>0.796633</td>\n",
              "      <td>-0.243973</td>\n",
              "      <td>-0.892326</td>\n",
              "      <td>0.447980</td>\n",
              "      <td>-0.589984</td>\n",
              "      <td>-0.002229</td>\n",
              "      <td>-0.010382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hold</td>\n",
              "      <td>-0.384540</td>\n",
              "      <td>0.279699</td>\n",
              "      <td>0.106182</td>\n",
              "      <td>-0.029910</td>\n",
              "      <td>1.073270</td>\n",
              "      <td>0.003156</td>\n",
              "      <td>-0.488824</td>\n",
              "      <td>0.405630</td>\n",
              "      <td>0.266080</td>\n",
              "      <td>0.095256</td>\n",
              "      <td>0.031279</td>\n",
              "      <td>1.155654</td>\n",
              "      <td>0.525354</td>\n",
              "      <td>0.520180</td>\n",
              "      <td>-0.271163</td>\n",
              "      <td>-0.181344</td>\n",
              "      <td>-1.008768</td>\n",
              "      <td>-0.465025</td>\n",
              "      <td>0.200859</td>\n",
              "      <td>-1.082525</td>\n",
              "      <td>-0.305292</td>\n",
              "      <td>0.215763</td>\n",
              "      <td>-0.541884</td>\n",
              "      <td>0.644441</td>\n",
              "      <td>0.576162</td>\n",
              "      <td>0.175921</td>\n",
              "      <td>0.025240</td>\n",
              "      <td>-1.351370</td>\n",
              "      <td>0.015212</td>\n",
              "      <td>0.270119</td>\n",
              "      <td>-0.187819</td>\n",
              "      <td>0.645505</td>\n",
              "      <td>0.362607</td>\n",
              "      <td>-0.428932</td>\n",
              "      <td>0.069556</td>\n",
              "      <td>0.123886</td>\n",
              "      <td>0.347831</td>\n",
              "      <td>-0.720449</td>\n",
              "      <td>-0.959762</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.815400</td>\n",
              "      <td>-0.120942</td>\n",
              "      <td>0.377571</td>\n",
              "      <td>0.218196</td>\n",
              "      <td>0.039915</td>\n",
              "      <td>1.465137</td>\n",
              "      <td>0.989916</td>\n",
              "      <td>-0.214278</td>\n",
              "      <td>-0.633975</td>\n",
              "      <td>0.554659</td>\n",
              "      <td>-0.785857</td>\n",
              "      <td>-1.371425</td>\n",
              "      <td>-0.918851</td>\n",
              "      <td>0.325933</td>\n",
              "      <td>0.632197</td>\n",
              "      <td>0.065679</td>\n",
              "      <td>0.102457</td>\n",
              "      <td>0.784508</td>\n",
              "      <td>0.155211</td>\n",
              "      <td>0.033452</td>\n",
              "      <td>-0.441959</td>\n",
              "      <td>0.014169</td>\n",
              "      <td>0.201251</td>\n",
              "      <td>-0.842049</td>\n",
              "      <td>0.564756</td>\n",
              "      <td>0.299082</td>\n",
              "      <td>-0.077638</td>\n",
              "      <td>-0.010976</td>\n",
              "      <td>-0.709649</td>\n",
              "      <td>0.938359</td>\n",
              "      <td>0.438167</td>\n",
              "      <td>0.223044</td>\n",
              "      <td>-0.222422</td>\n",
              "      <td>-0.087880</td>\n",
              "      <td>0.014681</td>\n",
              "      <td>0.221565</td>\n",
              "      <td>0.051895</td>\n",
              "      <td>-0.107228</td>\n",
              "      <td>-0.128941</td>\n",
              "      <td>0.116207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hold</td>\n",
              "      <td>-0.302616</td>\n",
              "      <td>0.148849</td>\n",
              "      <td>0.375761</td>\n",
              "      <td>-0.732169</td>\n",
              "      <td>0.438602</td>\n",
              "      <td>0.441591</td>\n",
              "      <td>0.465630</td>\n",
              "      <td>0.572733</td>\n",
              "      <td>-0.448347</td>\n",
              "      <td>0.244912</td>\n",
              "      <td>0.040643</td>\n",
              "      <td>0.643020</td>\n",
              "      <td>0.606962</td>\n",
              "      <td>-0.408092</td>\n",
              "      <td>-0.533262</td>\n",
              "      <td>-0.367083</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.468287</td>\n",
              "      <td>0.213556</td>\n",
              "      <td>0.044146</td>\n",
              "      <td>-0.312535</td>\n",
              "      <td>-0.533911</td>\n",
              "      <td>0.034080</td>\n",
              "      <td>-0.448310</td>\n",
              "      <td>0.606111</td>\n",
              "      <td>-0.210637</td>\n",
              "      <td>-0.088499</td>\n",
              "      <td>-0.189560</td>\n",
              "      <td>-0.249609</td>\n",
              "      <td>0.188828</td>\n",
              "      <td>-0.342214</td>\n",
              "      <td>1.184108</td>\n",
              "      <td>-0.638950</td>\n",
              "      <td>-0.164663</td>\n",
              "      <td>-0.425913</td>\n",
              "      <td>0.610394</td>\n",
              "      <td>-0.163890</td>\n",
              "      <td>-0.715222</td>\n",
              "      <td>-0.273624</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.417620</td>\n",
              "      <td>-0.567867</td>\n",
              "      <td>-0.351906</td>\n",
              "      <td>-0.609639</td>\n",
              "      <td>0.524588</td>\n",
              "      <td>0.825439</td>\n",
              "      <td>0.024019</td>\n",
              "      <td>0.418102</td>\n",
              "      <td>0.524916</td>\n",
              "      <td>-0.679347</td>\n",
              "      <td>-0.718317</td>\n",
              "      <td>-0.130137</td>\n",
              "      <td>0.238017</td>\n",
              "      <td>0.488869</td>\n",
              "      <td>-0.414903</td>\n",
              "      <td>-1.911417</td>\n",
              "      <td>0.223173</td>\n",
              "      <td>-0.159860</td>\n",
              "      <td>-0.460968</td>\n",
              "      <td>-0.092186</td>\n",
              "      <td>-0.358261</td>\n",
              "      <td>-0.432545</td>\n",
              "      <td>1.493156</td>\n",
              "      <td>-0.993699</td>\n",
              "      <td>0.522892</td>\n",
              "      <td>0.220661</td>\n",
              "      <td>0.028602</td>\n",
              "      <td>0.612950</td>\n",
              "      <td>0.358666</td>\n",
              "      <td>-0.704700</td>\n",
              "      <td>-0.156816</td>\n",
              "      <td>-0.337897</td>\n",
              "      <td>-0.468175</td>\n",
              "      <td>-0.484796</td>\n",
              "      <td>0.259535</td>\n",
              "      <td>0.017272</td>\n",
              "      <td>-0.173896</td>\n",
              "      <td>-0.084122</td>\n",
              "      <td>-0.465471</td>\n",
              "      <td>-0.381477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hold</td>\n",
              "      <td>0.311217</td>\n",
              "      <td>-0.353453</td>\n",
              "      <td>0.523998</td>\n",
              "      <td>0.608913</td>\n",
              "      <td>0.279207</td>\n",
              "      <td>-0.954849</td>\n",
              "      <td>0.077359</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>0.979836</td>\n",
              "      <td>-0.483236</td>\n",
              "      <td>-0.135463</td>\n",
              "      <td>1.569037</td>\n",
              "      <td>0.600532</td>\n",
              "      <td>0.978939</td>\n",
              "      <td>0.090648</td>\n",
              "      <td>0.269640</td>\n",
              "      <td>-0.092935</td>\n",
              "      <td>0.453170</td>\n",
              "      <td>-0.437131</td>\n",
              "      <td>-0.413042</td>\n",
              "      <td>-0.650756</td>\n",
              "      <td>-0.544429</td>\n",
              "      <td>0.814852</td>\n",
              "      <td>0.468384</td>\n",
              "      <td>0.575025</td>\n",
              "      <td>0.408669</td>\n",
              "      <td>-0.341693</td>\n",
              "      <td>0.625056</td>\n",
              "      <td>-0.369106</td>\n",
              "      <td>0.245226</td>\n",
              "      <td>-0.537825</td>\n",
              "      <td>0.472730</td>\n",
              "      <td>-0.262803</td>\n",
              "      <td>-0.480983</td>\n",
              "      <td>-0.556810</td>\n",
              "      <td>0.795559</td>\n",
              "      <td>0.223647</td>\n",
              "      <td>-0.371991</td>\n",
              "      <td>0.381469</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.558782</td>\n",
              "      <td>-0.522723</td>\n",
              "      <td>0.122187</td>\n",
              "      <td>-0.587809</td>\n",
              "      <td>0.318140</td>\n",
              "      <td>1.227732</td>\n",
              "      <td>0.431692</td>\n",
              "      <td>0.074814</td>\n",
              "      <td>0.309206</td>\n",
              "      <td>-0.371420</td>\n",
              "      <td>-1.315941</td>\n",
              "      <td>0.007644</td>\n",
              "      <td>-0.797448</td>\n",
              "      <td>-0.058738</td>\n",
              "      <td>-0.448677</td>\n",
              "      <td>-0.351645</td>\n",
              "      <td>-0.393221</td>\n",
              "      <td>0.309311</td>\n",
              "      <td>-0.352860</td>\n",
              "      <td>-0.140008</td>\n",
              "      <td>-0.356492</td>\n",
              "      <td>-0.231851</td>\n",
              "      <td>0.479473</td>\n",
              "      <td>-1.532238</td>\n",
              "      <td>0.381690</td>\n",
              "      <td>0.677481</td>\n",
              "      <td>-0.028643</td>\n",
              "      <td>0.716926</td>\n",
              "      <td>-0.411166</td>\n",
              "      <td>-0.065203</td>\n",
              "      <td>-0.238870</td>\n",
              "      <td>-1.550259</td>\n",
              "      <td>-0.603775</td>\n",
              "      <td>-0.717660</td>\n",
              "      <td>0.012977</td>\n",
              "      <td>-0.086806</td>\n",
              "      <td>-0.277069</td>\n",
              "      <td>-0.251942</td>\n",
              "      <td>0.208434</td>\n",
              "      <td>-0.613675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 769 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  Label         0         1         2  ...       764       765       766       767\n",
              "0  Hold  0.037546 -0.051923  0.344174  ... -0.325062  0.461889 -0.209296 -0.394507\n",
              "1  Hold -0.093125  1.055027 -0.438218  ...  0.447980 -0.589984 -0.002229 -0.010382\n",
              "2  Hold -0.384540  0.279699  0.106182  ...  0.051895 -0.107228 -0.128941  0.116207\n",
              "3  Hold -0.302616  0.148849  0.375761  ... -0.173896 -0.084122 -0.465471 -0.381477\n",
              "4  Hold  0.311217 -0.353453  0.523998  ... -0.277069 -0.251942  0.208434 -0.613675\n",
              "\n",
              "[5 rows x 769 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWCFCRCJOGlO",
        "outputId": "bc51afe5-ea95-46da-d413-60078eaa899d"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42813, 769)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL32Y-EoH01O"
      },
      "source": [
        "X = df.iloc[:, 1:768] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "cM9rYtZDHyjF",
        "outputId": "7280074f-73c1-4ea6-b88f-c4dcbd31aa64"
      },
      "source": [
        "pca = PCA().fit(X)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "xi = np.arange(1, 768, step=1)\n",
        "y = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "plt.ylim(0.0,1.1)\n",
        "plt.plot(xi, y, marker='o', linestyle='--', color='b')\n",
        "\n",
        "plt.xlabel('Number of Components')\n",
        "plt.xticks(np.arange(0, 750, step=50)) \n",
        "plt.ylabel('Cumulative variance (%)')\n",
        "plt.title('The number of components needed to explain variance')\n",
        "\n",
        "plt.axhline(y=0.95, color='r', linestyle='-')\n",
        "plt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n",
        "\n",
        "ax.grid(axis='x')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUrd-LKVJIVo"
      },
      "source": [
        "Y = df[['Label']] #dependent variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wX0-C8LKEtc"
      },
      "source": [
        "sm = SMOTE()\n",
        "X, Y = sm.fit_sample(X, Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D23raB_lGSdn"
      },
      "source": [
        "X = pd.DataFrame(X)\n",
        "Y = pd.DataFrame(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziLdJAEaFbxs"
      },
      "source": [
        "Result = pd.concat([X,Y],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMUs4ugTmAZC"
      },
      "source": [
        "pca = prince.PCA(\n",
        "    n_components=200,\n",
        "    n_iter=3,\n",
        "    rescale_with_mean=True,\n",
        "    rescale_with_std=True,\n",
        "    copy=True,\n",
        "    check_input=True,\n",
        "    engine='auto',\n",
        "    random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSdVgkirGKut"
      },
      "source": [
        "pca = pca.fit(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF9mmF_uIHzi"
      },
      "source": [
        "pca_result = pca.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "kWM1GJrgIS3Y",
        "outputId": "90ce8bf0-4d75-49e0-9fb7-9b20441726d6"
      },
      "source": [
        "pca_result.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12.700699</td>\n",
              "      <td>-8.299932</td>\n",
              "      <td>6.558541</td>\n",
              "      <td>17.225399</td>\n",
              "      <td>2.617590</td>\n",
              "      <td>6.089747</td>\n",
              "      <td>-1.069989</td>\n",
              "      <td>6.153290</td>\n",
              "      <td>-3.451504</td>\n",
              "      <td>-4.567675</td>\n",
              "      <td>-0.641041</td>\n",
              "      <td>3.122355</td>\n",
              "      <td>-4.444408</td>\n",
              "      <td>0.417771</td>\n",
              "      <td>2.937430</td>\n",
              "      <td>0.496325</td>\n",
              "      <td>4.047787</td>\n",
              "      <td>-6.236918</td>\n",
              "      <td>-2.211636</td>\n",
              "      <td>1.603723</td>\n",
              "      <td>1.594950</td>\n",
              "      <td>2.364862</td>\n",
              "      <td>-1.436210</td>\n",
              "      <td>-1.324844</td>\n",
              "      <td>-0.032512</td>\n",
              "      <td>-1.952071</td>\n",
              "      <td>3.882496</td>\n",
              "      <td>3.573540</td>\n",
              "      <td>2.345871</td>\n",
              "      <td>-1.206594</td>\n",
              "      <td>1.746366</td>\n",
              "      <td>2.446839</td>\n",
              "      <td>-0.300028</td>\n",
              "      <td>-3.143634</td>\n",
              "      <td>1.150723</td>\n",
              "      <td>1.830132</td>\n",
              "      <td>-0.889488</td>\n",
              "      <td>1.025174</td>\n",
              "      <td>-0.492093</td>\n",
              "      <td>-2.697144</td>\n",
              "      <td>...</td>\n",
              "      <td>0.202914</td>\n",
              "      <td>0.123997</td>\n",
              "      <td>0.163147</td>\n",
              "      <td>-0.480430</td>\n",
              "      <td>-0.820355</td>\n",
              "      <td>-0.261108</td>\n",
              "      <td>-0.156496</td>\n",
              "      <td>-0.593943</td>\n",
              "      <td>-0.544872</td>\n",
              "      <td>0.966506</td>\n",
              "      <td>-0.032903</td>\n",
              "      <td>-0.190533</td>\n",
              "      <td>-0.569823</td>\n",
              "      <td>-0.589293</td>\n",
              "      <td>-0.253224</td>\n",
              "      <td>-0.608259</td>\n",
              "      <td>0.298133</td>\n",
              "      <td>-0.229476</td>\n",
              "      <td>-0.489679</td>\n",
              "      <td>0.420181</td>\n",
              "      <td>0.151244</td>\n",
              "      <td>0.057697</td>\n",
              "      <td>-0.431654</td>\n",
              "      <td>-0.149882</td>\n",
              "      <td>-0.166682</td>\n",
              "      <td>0.713202</td>\n",
              "      <td>1.009072</td>\n",
              "      <td>-0.479161</td>\n",
              "      <td>0.208738</td>\n",
              "      <td>0.535228</td>\n",
              "      <td>-0.007463</td>\n",
              "      <td>-0.434316</td>\n",
              "      <td>-0.151852</td>\n",
              "      <td>1.292040</td>\n",
              "      <td>-0.758117</td>\n",
              "      <td>0.772478</td>\n",
              "      <td>0.498169</td>\n",
              "      <td>-0.187430</td>\n",
              "      <td>0.788442</td>\n",
              "      <td>-0.263061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-2.158684</td>\n",
              "      <td>1.851527</td>\n",
              "      <td>-9.460374</td>\n",
              "      <td>-7.499850</td>\n",
              "      <td>-7.869803</td>\n",
              "      <td>4.235964</td>\n",
              "      <td>-1.320477</td>\n",
              "      <td>-1.451778</td>\n",
              "      <td>-1.798413</td>\n",
              "      <td>9.188946</td>\n",
              "      <td>0.621427</td>\n",
              "      <td>0.818005</td>\n",
              "      <td>1.865170</td>\n",
              "      <td>0.144022</td>\n",
              "      <td>2.786874</td>\n",
              "      <td>0.854923</td>\n",
              "      <td>-5.495115</td>\n",
              "      <td>1.003885</td>\n",
              "      <td>2.643317</td>\n",
              "      <td>1.213968</td>\n",
              "      <td>-0.027097</td>\n",
              "      <td>0.831716</td>\n",
              "      <td>3.934653</td>\n",
              "      <td>1.278019</td>\n",
              "      <td>7.646634</td>\n",
              "      <td>0.605585</td>\n",
              "      <td>-1.733371</td>\n",
              "      <td>3.075658</td>\n",
              "      <td>-0.894962</td>\n",
              "      <td>0.656056</td>\n",
              "      <td>2.619279</td>\n",
              "      <td>-1.339799</td>\n",
              "      <td>-2.995423</td>\n",
              "      <td>-0.705933</td>\n",
              "      <td>1.488425</td>\n",
              "      <td>-2.486243</td>\n",
              "      <td>0.060293</td>\n",
              "      <td>-2.224922</td>\n",
              "      <td>0.663750</td>\n",
              "      <td>0.368017</td>\n",
              "      <td>...</td>\n",
              "      <td>1.413317</td>\n",
              "      <td>-0.777817</td>\n",
              "      <td>0.176276</td>\n",
              "      <td>0.479655</td>\n",
              "      <td>0.315247</td>\n",
              "      <td>0.626059</td>\n",
              "      <td>-0.965004</td>\n",
              "      <td>-0.505149</td>\n",
              "      <td>0.348791</td>\n",
              "      <td>0.107880</td>\n",
              "      <td>-0.056914</td>\n",
              "      <td>-0.674916</td>\n",
              "      <td>-0.272391</td>\n",
              "      <td>0.189684</td>\n",
              "      <td>0.526639</td>\n",
              "      <td>0.642777</td>\n",
              "      <td>0.985227</td>\n",
              "      <td>1.290432</td>\n",
              "      <td>0.162069</td>\n",
              "      <td>-0.389516</td>\n",
              "      <td>0.302937</td>\n",
              "      <td>-0.290781</td>\n",
              "      <td>-0.658492</td>\n",
              "      <td>-0.819479</td>\n",
              "      <td>1.134735</td>\n",
              "      <td>-0.218641</td>\n",
              "      <td>0.241894</td>\n",
              "      <td>-0.255580</td>\n",
              "      <td>-0.768480</td>\n",
              "      <td>-0.697873</td>\n",
              "      <td>0.228334</td>\n",
              "      <td>-0.352090</td>\n",
              "      <td>0.432015</td>\n",
              "      <td>-0.371034</td>\n",
              "      <td>0.005297</td>\n",
              "      <td>0.062790</td>\n",
              "      <td>0.365472</td>\n",
              "      <td>0.297483</td>\n",
              "      <td>0.425199</td>\n",
              "      <td>0.102069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11.071089</td>\n",
              "      <td>0.221805</td>\n",
              "      <td>13.224041</td>\n",
              "      <td>-2.953081</td>\n",
              "      <td>-10.490442</td>\n",
              "      <td>-7.344750</td>\n",
              "      <td>-4.254249</td>\n",
              "      <td>2.962356</td>\n",
              "      <td>6.035651</td>\n",
              "      <td>4.224363</td>\n",
              "      <td>-0.064840</td>\n",
              "      <td>-4.583609</td>\n",
              "      <td>-0.210560</td>\n",
              "      <td>-1.742691</td>\n",
              "      <td>-4.504027</td>\n",
              "      <td>-1.824371</td>\n",
              "      <td>1.736423</td>\n",
              "      <td>-0.280585</td>\n",
              "      <td>-0.508200</td>\n",
              "      <td>-2.694558</td>\n",
              "      <td>-1.150282</td>\n",
              "      <td>0.178123</td>\n",
              "      <td>2.849542</td>\n",
              "      <td>-2.118143</td>\n",
              "      <td>2.358878</td>\n",
              "      <td>1.415255</td>\n",
              "      <td>-0.316611</td>\n",
              "      <td>-4.039049</td>\n",
              "      <td>-1.838827</td>\n",
              "      <td>-2.608750</td>\n",
              "      <td>-0.063564</td>\n",
              "      <td>-1.966190</td>\n",
              "      <td>-2.454464</td>\n",
              "      <td>0.131726</td>\n",
              "      <td>3.324168</td>\n",
              "      <td>-1.592318</td>\n",
              "      <td>-0.986852</td>\n",
              "      <td>-0.102308</td>\n",
              "      <td>-2.074929</td>\n",
              "      <td>5.760116</td>\n",
              "      <td>...</td>\n",
              "      <td>0.425498</td>\n",
              "      <td>-0.019514</td>\n",
              "      <td>-0.359844</td>\n",
              "      <td>-0.062414</td>\n",
              "      <td>0.724456</td>\n",
              "      <td>0.715110</td>\n",
              "      <td>-0.719960</td>\n",
              "      <td>-0.268870</td>\n",
              "      <td>1.471457</td>\n",
              "      <td>0.220661</td>\n",
              "      <td>1.427179</td>\n",
              "      <td>0.250413</td>\n",
              "      <td>0.256336</td>\n",
              "      <td>0.237007</td>\n",
              "      <td>-1.021833</td>\n",
              "      <td>-0.584025</td>\n",
              "      <td>1.017911</td>\n",
              "      <td>0.363634</td>\n",
              "      <td>-0.587504</td>\n",
              "      <td>-0.833844</td>\n",
              "      <td>1.200305</td>\n",
              "      <td>0.347355</td>\n",
              "      <td>-0.291190</td>\n",
              "      <td>0.235435</td>\n",
              "      <td>0.239445</td>\n",
              "      <td>-0.738509</td>\n",
              "      <td>0.240442</td>\n",
              "      <td>0.580533</td>\n",
              "      <td>-0.078808</td>\n",
              "      <td>0.285774</td>\n",
              "      <td>-0.085894</td>\n",
              "      <td>0.405525</td>\n",
              "      <td>-0.197349</td>\n",
              "      <td>-0.523136</td>\n",
              "      <td>-0.476313</td>\n",
              "      <td>-0.449337</td>\n",
              "      <td>-0.254493</td>\n",
              "      <td>0.579220</td>\n",
              "      <td>-0.375671</td>\n",
              "      <td>0.473883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-12.372115</td>\n",
              "      <td>-2.437640</td>\n",
              "      <td>-1.443254</td>\n",
              "      <td>8.683937</td>\n",
              "      <td>2.866667</td>\n",
              "      <td>-2.294348</td>\n",
              "      <td>-3.939452</td>\n",
              "      <td>-9.951083</td>\n",
              "      <td>4.773922</td>\n",
              "      <td>-3.761780</td>\n",
              "      <td>0.534116</td>\n",
              "      <td>-0.799225</td>\n",
              "      <td>0.261206</td>\n",
              "      <td>2.264291</td>\n",
              "      <td>-4.512898</td>\n",
              "      <td>2.149856</td>\n",
              "      <td>4.434140</td>\n",
              "      <td>-0.522778</td>\n",
              "      <td>2.140820</td>\n",
              "      <td>4.758262</td>\n",
              "      <td>0.634980</td>\n",
              "      <td>1.349484</td>\n",
              "      <td>-1.497353</td>\n",
              "      <td>-0.561645</td>\n",
              "      <td>2.567172</td>\n",
              "      <td>-0.309783</td>\n",
              "      <td>1.078642</td>\n",
              "      <td>0.024205</td>\n",
              "      <td>3.366644</td>\n",
              "      <td>1.433821</td>\n",
              "      <td>-0.209207</td>\n",
              "      <td>0.582896</td>\n",
              "      <td>-1.489728</td>\n",
              "      <td>1.707101</td>\n",
              "      <td>-1.478057</td>\n",
              "      <td>2.159803</td>\n",
              "      <td>-2.611288</td>\n",
              "      <td>0.087503</td>\n",
              "      <td>-1.226977</td>\n",
              "      <td>-0.844349</td>\n",
              "      <td>...</td>\n",
              "      <td>0.576795</td>\n",
              "      <td>0.262232</td>\n",
              "      <td>-0.426399</td>\n",
              "      <td>0.434378</td>\n",
              "      <td>-0.166398</td>\n",
              "      <td>0.652389</td>\n",
              "      <td>0.140516</td>\n",
              "      <td>-1.081979</td>\n",
              "      <td>-0.118532</td>\n",
              "      <td>0.395930</td>\n",
              "      <td>-0.197488</td>\n",
              "      <td>-0.126618</td>\n",
              "      <td>-0.055197</td>\n",
              "      <td>-0.275222</td>\n",
              "      <td>-0.584999</td>\n",
              "      <td>-0.197778</td>\n",
              "      <td>0.018790</td>\n",
              "      <td>-0.526184</td>\n",
              "      <td>0.567367</td>\n",
              "      <td>-0.871824</td>\n",
              "      <td>0.693571</td>\n",
              "      <td>-0.027300</td>\n",
              "      <td>0.031355</td>\n",
              "      <td>0.018616</td>\n",
              "      <td>0.409064</td>\n",
              "      <td>-0.329405</td>\n",
              "      <td>-0.375802</td>\n",
              "      <td>-0.319001</td>\n",
              "      <td>0.068506</td>\n",
              "      <td>-0.370460</td>\n",
              "      <td>0.249449</td>\n",
              "      <td>-0.254244</td>\n",
              "      <td>0.024504</td>\n",
              "      <td>-0.822276</td>\n",
              "      <td>-0.142006</td>\n",
              "      <td>-0.333292</td>\n",
              "      <td>0.741228</td>\n",
              "      <td>0.074993</td>\n",
              "      <td>-0.468714</td>\n",
              "      <td>0.041962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.827015</td>\n",
              "      <td>-10.785181</td>\n",
              "      <td>2.608567</td>\n",
              "      <td>-0.047342</td>\n",
              "      <td>-0.815054</td>\n",
              "      <td>12.288722</td>\n",
              "      <td>-3.898094</td>\n",
              "      <td>-2.562877</td>\n",
              "      <td>1.353505</td>\n",
              "      <td>-7.151824</td>\n",
              "      <td>7.013355</td>\n",
              "      <td>-2.903310</td>\n",
              "      <td>-1.661344</td>\n",
              "      <td>-0.043495</td>\n",
              "      <td>-9.835423</td>\n",
              "      <td>3.321440</td>\n",
              "      <td>-3.776740</td>\n",
              "      <td>-5.286874</td>\n",
              "      <td>2.486899</td>\n",
              "      <td>-0.168997</td>\n",
              "      <td>-3.209220</td>\n",
              "      <td>0.600681</td>\n",
              "      <td>0.872221</td>\n",
              "      <td>-0.669533</td>\n",
              "      <td>0.139525</td>\n",
              "      <td>2.407059</td>\n",
              "      <td>1.045532</td>\n",
              "      <td>-5.043071</td>\n",
              "      <td>-3.996605</td>\n",
              "      <td>4.788004</td>\n",
              "      <td>-0.324623</td>\n",
              "      <td>-0.919464</td>\n",
              "      <td>2.918615</td>\n",
              "      <td>-1.013615</td>\n",
              "      <td>-1.807746</td>\n",
              "      <td>-4.685468</td>\n",
              "      <td>1.773679</td>\n",
              "      <td>-0.502465</td>\n",
              "      <td>-1.703052</td>\n",
              "      <td>-0.085503</td>\n",
              "      <td>...</td>\n",
              "      <td>0.114562</td>\n",
              "      <td>0.056780</td>\n",
              "      <td>0.025437</td>\n",
              "      <td>-0.067538</td>\n",
              "      <td>0.373623</td>\n",
              "      <td>0.527842</td>\n",
              "      <td>-0.168078</td>\n",
              "      <td>-0.075125</td>\n",
              "      <td>-0.073729</td>\n",
              "      <td>1.347858</td>\n",
              "      <td>-0.195141</td>\n",
              "      <td>0.601979</td>\n",
              "      <td>0.489727</td>\n",
              "      <td>0.032282</td>\n",
              "      <td>-0.549745</td>\n",
              "      <td>-0.634523</td>\n",
              "      <td>0.095906</td>\n",
              "      <td>0.672543</td>\n",
              "      <td>-0.003679</td>\n",
              "      <td>-0.317745</td>\n",
              "      <td>0.358905</td>\n",
              "      <td>0.079565</td>\n",
              "      <td>-0.204482</td>\n",
              "      <td>0.063764</td>\n",
              "      <td>0.022546</td>\n",
              "      <td>0.017794</td>\n",
              "      <td>-0.485069</td>\n",
              "      <td>-1.495561</td>\n",
              "      <td>-1.054361</td>\n",
              "      <td>0.323403</td>\n",
              "      <td>-1.108812</td>\n",
              "      <td>0.871853</td>\n",
              "      <td>-0.026307</td>\n",
              "      <td>0.602055</td>\n",
              "      <td>-0.345336</td>\n",
              "      <td>-0.414343</td>\n",
              "      <td>1.205263</td>\n",
              "      <td>-1.472963</td>\n",
              "      <td>-0.368092</td>\n",
              "      <td>-0.426845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 200 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0          1          2    ...       197       198       199\n",
              "0  12.700699  -8.299932   6.558541  ... -0.187430  0.788442 -0.263061\n",
              "1  -2.158684   1.851527  -9.460374  ...  0.297483  0.425199  0.102069\n",
              "2  11.071089   0.221805  13.224041  ...  0.579220 -0.375671  0.473883\n",
              "3 -12.372115  -2.437640  -1.443254  ...  0.074993 -0.468714  0.041962\n",
              "4   2.827015 -10.785181   2.608567  ... -1.472963 -0.368092 -0.426845\n",
              "\n",
              "[5 rows x 200 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHrGr4ShIX5c"
      },
      "source": [
        "#pca_result.to_csv('/content/drive/MyDrive/BERT + STOCK /Balanced Data - PCA 200.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6aw-rClJdrl"
      },
      "source": [
        "Y.rename(columns={0:'Label'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BweoKHLI95y"
      },
      "source": [
        "balanced_data = pd.concat([pca_result,Y], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrHeI3EnNmh3",
        "outputId": "d5fbf0b7-f034-41eb-bb18-2976f65695c3"
      },
      "source": [
        "Y[\"Label\"] = Y[\"Label\"].astype('category')\n",
        "Y.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label    category\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cMBW_3zN6Mk"
      },
      "source": [
        "Y[\"Label\"] = Y[\"Label\"].cat.codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k3Pw4B6TjW0"
      },
      "source": [
        "scaler = MinMaxScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EctVbBQYTr3x",
        "outputId": "42eef12a-7726-4327-a3be-5ec80f802fb3"
      },
      "source": [
        "scaler.fit(pca_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler(copy=True, feature_range=(0, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weFLi3w5TxwL"
      },
      "source": [
        "X_scaled = scaler.transform(pca_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYJLqvhHW4aj"
      },
      "source": [
        "X_scaled = pd.DataFrame(X_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kokHr08pT4Gh"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.20, random_state=42,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "8nrQL5dWWj_h",
        "outputId": "6b037e86-d555-4db6-a887-f9cb95ecc013"
      },
      "source": [
        "pca_result.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12.700699</td>\n",
              "      <td>-8.299932</td>\n",
              "      <td>6.558541</td>\n",
              "      <td>17.225399</td>\n",
              "      <td>2.617590</td>\n",
              "      <td>6.089747</td>\n",
              "      <td>-1.069989</td>\n",
              "      <td>6.153290</td>\n",
              "      <td>-3.451504</td>\n",
              "      <td>-4.567675</td>\n",
              "      <td>-0.641041</td>\n",
              "      <td>3.122355</td>\n",
              "      <td>-4.444408</td>\n",
              "      <td>0.417771</td>\n",
              "      <td>2.937430</td>\n",
              "      <td>0.496325</td>\n",
              "      <td>4.047787</td>\n",
              "      <td>-6.236918</td>\n",
              "      <td>-2.211636</td>\n",
              "      <td>1.603723</td>\n",
              "      <td>1.594950</td>\n",
              "      <td>2.364862</td>\n",
              "      <td>-1.436210</td>\n",
              "      <td>-1.324844</td>\n",
              "      <td>-0.032512</td>\n",
              "      <td>-1.952071</td>\n",
              "      <td>3.882496</td>\n",
              "      <td>3.573540</td>\n",
              "      <td>2.345871</td>\n",
              "      <td>-1.206594</td>\n",
              "      <td>1.746366</td>\n",
              "      <td>2.446839</td>\n",
              "      <td>-0.300028</td>\n",
              "      <td>-3.143634</td>\n",
              "      <td>1.150723</td>\n",
              "      <td>1.830132</td>\n",
              "      <td>-0.889488</td>\n",
              "      <td>1.025174</td>\n",
              "      <td>-0.492093</td>\n",
              "      <td>-2.697144</td>\n",
              "      <td>...</td>\n",
              "      <td>0.202914</td>\n",
              "      <td>0.123997</td>\n",
              "      <td>0.163147</td>\n",
              "      <td>-0.480430</td>\n",
              "      <td>-0.820355</td>\n",
              "      <td>-0.261108</td>\n",
              "      <td>-0.156496</td>\n",
              "      <td>-0.593943</td>\n",
              "      <td>-0.544872</td>\n",
              "      <td>0.966506</td>\n",
              "      <td>-0.032903</td>\n",
              "      <td>-0.190533</td>\n",
              "      <td>-0.569823</td>\n",
              "      <td>-0.589293</td>\n",
              "      <td>-0.253224</td>\n",
              "      <td>-0.608259</td>\n",
              "      <td>0.298133</td>\n",
              "      <td>-0.229476</td>\n",
              "      <td>-0.489679</td>\n",
              "      <td>0.420181</td>\n",
              "      <td>0.151244</td>\n",
              "      <td>0.057697</td>\n",
              "      <td>-0.431654</td>\n",
              "      <td>-0.149882</td>\n",
              "      <td>-0.166682</td>\n",
              "      <td>0.713202</td>\n",
              "      <td>1.009072</td>\n",
              "      <td>-0.479161</td>\n",
              "      <td>0.208738</td>\n",
              "      <td>0.535228</td>\n",
              "      <td>-0.007463</td>\n",
              "      <td>-0.434316</td>\n",
              "      <td>-0.151852</td>\n",
              "      <td>1.292040</td>\n",
              "      <td>-0.758117</td>\n",
              "      <td>0.772478</td>\n",
              "      <td>0.498169</td>\n",
              "      <td>-0.187430</td>\n",
              "      <td>0.788442</td>\n",
              "      <td>-0.263061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-2.158684</td>\n",
              "      <td>1.851527</td>\n",
              "      <td>-9.460374</td>\n",
              "      <td>-7.499850</td>\n",
              "      <td>-7.869803</td>\n",
              "      <td>4.235964</td>\n",
              "      <td>-1.320477</td>\n",
              "      <td>-1.451778</td>\n",
              "      <td>-1.798413</td>\n",
              "      <td>9.188946</td>\n",
              "      <td>0.621427</td>\n",
              "      <td>0.818005</td>\n",
              "      <td>1.865170</td>\n",
              "      <td>0.144022</td>\n",
              "      <td>2.786874</td>\n",
              "      <td>0.854923</td>\n",
              "      <td>-5.495115</td>\n",
              "      <td>1.003885</td>\n",
              "      <td>2.643317</td>\n",
              "      <td>1.213968</td>\n",
              "      <td>-0.027097</td>\n",
              "      <td>0.831716</td>\n",
              "      <td>3.934653</td>\n",
              "      <td>1.278019</td>\n",
              "      <td>7.646634</td>\n",
              "      <td>0.605585</td>\n",
              "      <td>-1.733371</td>\n",
              "      <td>3.075658</td>\n",
              "      <td>-0.894962</td>\n",
              "      <td>0.656056</td>\n",
              "      <td>2.619279</td>\n",
              "      <td>-1.339799</td>\n",
              "      <td>-2.995423</td>\n",
              "      <td>-0.705933</td>\n",
              "      <td>1.488425</td>\n",
              "      <td>-2.486243</td>\n",
              "      <td>0.060293</td>\n",
              "      <td>-2.224922</td>\n",
              "      <td>0.663750</td>\n",
              "      <td>0.368017</td>\n",
              "      <td>...</td>\n",
              "      <td>1.413317</td>\n",
              "      <td>-0.777817</td>\n",
              "      <td>0.176276</td>\n",
              "      <td>0.479655</td>\n",
              "      <td>0.315247</td>\n",
              "      <td>0.626059</td>\n",
              "      <td>-0.965004</td>\n",
              "      <td>-0.505149</td>\n",
              "      <td>0.348791</td>\n",
              "      <td>0.107880</td>\n",
              "      <td>-0.056914</td>\n",
              "      <td>-0.674916</td>\n",
              "      <td>-0.272391</td>\n",
              "      <td>0.189684</td>\n",
              "      <td>0.526639</td>\n",
              "      <td>0.642777</td>\n",
              "      <td>0.985227</td>\n",
              "      <td>1.290432</td>\n",
              "      <td>0.162069</td>\n",
              "      <td>-0.389516</td>\n",
              "      <td>0.302937</td>\n",
              "      <td>-0.290781</td>\n",
              "      <td>-0.658492</td>\n",
              "      <td>-0.819479</td>\n",
              "      <td>1.134735</td>\n",
              "      <td>-0.218641</td>\n",
              "      <td>0.241894</td>\n",
              "      <td>-0.255580</td>\n",
              "      <td>-0.768480</td>\n",
              "      <td>-0.697873</td>\n",
              "      <td>0.228334</td>\n",
              "      <td>-0.352090</td>\n",
              "      <td>0.432015</td>\n",
              "      <td>-0.371034</td>\n",
              "      <td>0.005297</td>\n",
              "      <td>0.062790</td>\n",
              "      <td>0.365472</td>\n",
              "      <td>0.297483</td>\n",
              "      <td>0.425199</td>\n",
              "      <td>0.102069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11.071089</td>\n",
              "      <td>0.221805</td>\n",
              "      <td>13.224041</td>\n",
              "      <td>-2.953081</td>\n",
              "      <td>-10.490442</td>\n",
              "      <td>-7.344750</td>\n",
              "      <td>-4.254249</td>\n",
              "      <td>2.962356</td>\n",
              "      <td>6.035651</td>\n",
              "      <td>4.224363</td>\n",
              "      <td>-0.064840</td>\n",
              "      <td>-4.583609</td>\n",
              "      <td>-0.210560</td>\n",
              "      <td>-1.742691</td>\n",
              "      <td>-4.504027</td>\n",
              "      <td>-1.824371</td>\n",
              "      <td>1.736423</td>\n",
              "      <td>-0.280585</td>\n",
              "      <td>-0.508200</td>\n",
              "      <td>-2.694558</td>\n",
              "      <td>-1.150282</td>\n",
              "      <td>0.178123</td>\n",
              "      <td>2.849542</td>\n",
              "      <td>-2.118143</td>\n",
              "      <td>2.358878</td>\n",
              "      <td>1.415255</td>\n",
              "      <td>-0.316611</td>\n",
              "      <td>-4.039049</td>\n",
              "      <td>-1.838827</td>\n",
              "      <td>-2.608750</td>\n",
              "      <td>-0.063564</td>\n",
              "      <td>-1.966190</td>\n",
              "      <td>-2.454464</td>\n",
              "      <td>0.131726</td>\n",
              "      <td>3.324168</td>\n",
              "      <td>-1.592318</td>\n",
              "      <td>-0.986852</td>\n",
              "      <td>-0.102308</td>\n",
              "      <td>-2.074929</td>\n",
              "      <td>5.760116</td>\n",
              "      <td>...</td>\n",
              "      <td>0.425498</td>\n",
              "      <td>-0.019514</td>\n",
              "      <td>-0.359844</td>\n",
              "      <td>-0.062414</td>\n",
              "      <td>0.724456</td>\n",
              "      <td>0.715110</td>\n",
              "      <td>-0.719960</td>\n",
              "      <td>-0.268870</td>\n",
              "      <td>1.471457</td>\n",
              "      <td>0.220661</td>\n",
              "      <td>1.427179</td>\n",
              "      <td>0.250413</td>\n",
              "      <td>0.256336</td>\n",
              "      <td>0.237007</td>\n",
              "      <td>-1.021833</td>\n",
              "      <td>-0.584025</td>\n",
              "      <td>1.017911</td>\n",
              "      <td>0.363634</td>\n",
              "      <td>-0.587504</td>\n",
              "      <td>-0.833844</td>\n",
              "      <td>1.200305</td>\n",
              "      <td>0.347355</td>\n",
              "      <td>-0.291190</td>\n",
              "      <td>0.235435</td>\n",
              "      <td>0.239445</td>\n",
              "      <td>-0.738509</td>\n",
              "      <td>0.240442</td>\n",
              "      <td>0.580533</td>\n",
              "      <td>-0.078808</td>\n",
              "      <td>0.285774</td>\n",
              "      <td>-0.085894</td>\n",
              "      <td>0.405525</td>\n",
              "      <td>-0.197349</td>\n",
              "      <td>-0.523136</td>\n",
              "      <td>-0.476313</td>\n",
              "      <td>-0.449337</td>\n",
              "      <td>-0.254493</td>\n",
              "      <td>0.579220</td>\n",
              "      <td>-0.375671</td>\n",
              "      <td>0.473883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-12.372115</td>\n",
              "      <td>-2.437640</td>\n",
              "      <td>-1.443254</td>\n",
              "      <td>8.683937</td>\n",
              "      <td>2.866667</td>\n",
              "      <td>-2.294348</td>\n",
              "      <td>-3.939452</td>\n",
              "      <td>-9.951083</td>\n",
              "      <td>4.773922</td>\n",
              "      <td>-3.761780</td>\n",
              "      <td>0.534116</td>\n",
              "      <td>-0.799225</td>\n",
              "      <td>0.261206</td>\n",
              "      <td>2.264291</td>\n",
              "      <td>-4.512898</td>\n",
              "      <td>2.149856</td>\n",
              "      <td>4.434140</td>\n",
              "      <td>-0.522778</td>\n",
              "      <td>2.140820</td>\n",
              "      <td>4.758262</td>\n",
              "      <td>0.634980</td>\n",
              "      <td>1.349484</td>\n",
              "      <td>-1.497353</td>\n",
              "      <td>-0.561645</td>\n",
              "      <td>2.567172</td>\n",
              "      <td>-0.309783</td>\n",
              "      <td>1.078642</td>\n",
              "      <td>0.024205</td>\n",
              "      <td>3.366644</td>\n",
              "      <td>1.433821</td>\n",
              "      <td>-0.209207</td>\n",
              "      <td>0.582896</td>\n",
              "      <td>-1.489728</td>\n",
              "      <td>1.707101</td>\n",
              "      <td>-1.478057</td>\n",
              "      <td>2.159803</td>\n",
              "      <td>-2.611288</td>\n",
              "      <td>0.087503</td>\n",
              "      <td>-1.226977</td>\n",
              "      <td>-0.844349</td>\n",
              "      <td>...</td>\n",
              "      <td>0.576795</td>\n",
              "      <td>0.262232</td>\n",
              "      <td>-0.426399</td>\n",
              "      <td>0.434378</td>\n",
              "      <td>-0.166398</td>\n",
              "      <td>0.652389</td>\n",
              "      <td>0.140516</td>\n",
              "      <td>-1.081979</td>\n",
              "      <td>-0.118532</td>\n",
              "      <td>0.395930</td>\n",
              "      <td>-0.197488</td>\n",
              "      <td>-0.126618</td>\n",
              "      <td>-0.055197</td>\n",
              "      <td>-0.275222</td>\n",
              "      <td>-0.584999</td>\n",
              "      <td>-0.197778</td>\n",
              "      <td>0.018790</td>\n",
              "      <td>-0.526184</td>\n",
              "      <td>0.567367</td>\n",
              "      <td>-0.871824</td>\n",
              "      <td>0.693571</td>\n",
              "      <td>-0.027300</td>\n",
              "      <td>0.031355</td>\n",
              "      <td>0.018616</td>\n",
              "      <td>0.409064</td>\n",
              "      <td>-0.329405</td>\n",
              "      <td>-0.375802</td>\n",
              "      <td>-0.319001</td>\n",
              "      <td>0.068506</td>\n",
              "      <td>-0.370460</td>\n",
              "      <td>0.249449</td>\n",
              "      <td>-0.254244</td>\n",
              "      <td>0.024504</td>\n",
              "      <td>-0.822276</td>\n",
              "      <td>-0.142006</td>\n",
              "      <td>-0.333292</td>\n",
              "      <td>0.741228</td>\n",
              "      <td>0.074993</td>\n",
              "      <td>-0.468714</td>\n",
              "      <td>0.041962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.827015</td>\n",
              "      <td>-10.785181</td>\n",
              "      <td>2.608567</td>\n",
              "      <td>-0.047342</td>\n",
              "      <td>-0.815054</td>\n",
              "      <td>12.288722</td>\n",
              "      <td>-3.898094</td>\n",
              "      <td>-2.562877</td>\n",
              "      <td>1.353505</td>\n",
              "      <td>-7.151824</td>\n",
              "      <td>7.013355</td>\n",
              "      <td>-2.903310</td>\n",
              "      <td>-1.661344</td>\n",
              "      <td>-0.043495</td>\n",
              "      <td>-9.835423</td>\n",
              "      <td>3.321440</td>\n",
              "      <td>-3.776740</td>\n",
              "      <td>-5.286874</td>\n",
              "      <td>2.486899</td>\n",
              "      <td>-0.168997</td>\n",
              "      <td>-3.209220</td>\n",
              "      <td>0.600681</td>\n",
              "      <td>0.872221</td>\n",
              "      <td>-0.669533</td>\n",
              "      <td>0.139525</td>\n",
              "      <td>2.407059</td>\n",
              "      <td>1.045532</td>\n",
              "      <td>-5.043071</td>\n",
              "      <td>-3.996605</td>\n",
              "      <td>4.788004</td>\n",
              "      <td>-0.324623</td>\n",
              "      <td>-0.919464</td>\n",
              "      <td>2.918615</td>\n",
              "      <td>-1.013615</td>\n",
              "      <td>-1.807746</td>\n",
              "      <td>-4.685468</td>\n",
              "      <td>1.773679</td>\n",
              "      <td>-0.502465</td>\n",
              "      <td>-1.703052</td>\n",
              "      <td>-0.085503</td>\n",
              "      <td>...</td>\n",
              "      <td>0.114562</td>\n",
              "      <td>0.056780</td>\n",
              "      <td>0.025437</td>\n",
              "      <td>-0.067538</td>\n",
              "      <td>0.373623</td>\n",
              "      <td>0.527842</td>\n",
              "      <td>-0.168078</td>\n",
              "      <td>-0.075125</td>\n",
              "      <td>-0.073729</td>\n",
              "      <td>1.347858</td>\n",
              "      <td>-0.195141</td>\n",
              "      <td>0.601979</td>\n",
              "      <td>0.489727</td>\n",
              "      <td>0.032282</td>\n",
              "      <td>-0.549745</td>\n",
              "      <td>-0.634523</td>\n",
              "      <td>0.095906</td>\n",
              "      <td>0.672543</td>\n",
              "      <td>-0.003679</td>\n",
              "      <td>-0.317745</td>\n",
              "      <td>0.358905</td>\n",
              "      <td>0.079565</td>\n",
              "      <td>-0.204482</td>\n",
              "      <td>0.063764</td>\n",
              "      <td>0.022546</td>\n",
              "      <td>0.017794</td>\n",
              "      <td>-0.485069</td>\n",
              "      <td>-1.495561</td>\n",
              "      <td>-1.054361</td>\n",
              "      <td>0.323403</td>\n",
              "      <td>-1.108812</td>\n",
              "      <td>0.871853</td>\n",
              "      <td>-0.026307</td>\n",
              "      <td>0.602055</td>\n",
              "      <td>-0.345336</td>\n",
              "      <td>-0.414343</td>\n",
              "      <td>1.205263</td>\n",
              "      <td>-1.472963</td>\n",
              "      <td>-0.368092</td>\n",
              "      <td>-0.426845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 200 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0          1          2    ...       197       198       199\n",
              "0  12.700699  -8.299932   6.558541  ... -0.187430  0.788442 -0.263061\n",
              "1  -2.158684   1.851527  -9.460374  ...  0.297483  0.425199  0.102069\n",
              "2  11.071089   0.221805  13.224041  ...  0.579220 -0.375671  0.473883\n",
              "3 -12.372115  -2.437640  -1.443254  ...  0.074993 -0.468714  0.041962\n",
              "4   2.827015 -10.785181   2.608567  ... -1.472963 -0.368092 -0.426845\n",
              "\n",
              "[5 rows x 200 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "h2Zvy7EZWf9E",
        "outputId": "d75e3aec-3184-4817-b45d-f0e4a5c86af3"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53032</th>\n",
              "      <td>0.265250</td>\n",
              "      <td>0.452413</td>\n",
              "      <td>0.506515</td>\n",
              "      <td>0.247752</td>\n",
              "      <td>0.437040</td>\n",
              "      <td>0.667797</td>\n",
              "      <td>0.308573</td>\n",
              "      <td>0.386297</td>\n",
              "      <td>0.580953</td>\n",
              "      <td>0.529398</td>\n",
              "      <td>0.441002</td>\n",
              "      <td>0.463760</td>\n",
              "      <td>0.387415</td>\n",
              "      <td>0.384107</td>\n",
              "      <td>0.357585</td>\n",
              "      <td>0.549781</td>\n",
              "      <td>0.568225</td>\n",
              "      <td>0.609441</td>\n",
              "      <td>0.472051</td>\n",
              "      <td>0.381484</td>\n",
              "      <td>0.371350</td>\n",
              "      <td>0.728327</td>\n",
              "      <td>0.328479</td>\n",
              "      <td>0.515125</td>\n",
              "      <td>0.423560</td>\n",
              "      <td>0.426272</td>\n",
              "      <td>0.623253</td>\n",
              "      <td>0.368044</td>\n",
              "      <td>0.592026</td>\n",
              "      <td>0.528846</td>\n",
              "      <td>0.458809</td>\n",
              "      <td>0.413037</td>\n",
              "      <td>0.502787</td>\n",
              "      <td>0.536755</td>\n",
              "      <td>0.392158</td>\n",
              "      <td>0.345619</td>\n",
              "      <td>0.497285</td>\n",
              "      <td>0.324668</td>\n",
              "      <td>0.545308</td>\n",
              "      <td>0.478278</td>\n",
              "      <td>...</td>\n",
              "      <td>0.447193</td>\n",
              "      <td>0.448621</td>\n",
              "      <td>0.506694</td>\n",
              "      <td>0.454508</td>\n",
              "      <td>0.625305</td>\n",
              "      <td>0.466767</td>\n",
              "      <td>0.537564</td>\n",
              "      <td>0.375874</td>\n",
              "      <td>0.455058</td>\n",
              "      <td>0.490999</td>\n",
              "      <td>0.415048</td>\n",
              "      <td>0.407827</td>\n",
              "      <td>0.408627</td>\n",
              "      <td>0.464719</td>\n",
              "      <td>0.576258</td>\n",
              "      <td>0.480772</td>\n",
              "      <td>0.407573</td>\n",
              "      <td>0.427758</td>\n",
              "      <td>0.485733</td>\n",
              "      <td>0.488008</td>\n",
              "      <td>0.458634</td>\n",
              "      <td>0.568877</td>\n",
              "      <td>0.464195</td>\n",
              "      <td>0.544534</td>\n",
              "      <td>0.365437</td>\n",
              "      <td>0.549489</td>\n",
              "      <td>0.341876</td>\n",
              "      <td>0.474177</td>\n",
              "      <td>0.505838</td>\n",
              "      <td>0.315185</td>\n",
              "      <td>0.570349</td>\n",
              "      <td>0.394297</td>\n",
              "      <td>0.519186</td>\n",
              "      <td>0.403904</td>\n",
              "      <td>0.498212</td>\n",
              "      <td>0.574520</td>\n",
              "      <td>0.484430</td>\n",
              "      <td>0.525188</td>\n",
              "      <td>0.502132</td>\n",
              "      <td>0.434729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103777</th>\n",
              "      <td>0.527883</td>\n",
              "      <td>0.309239</td>\n",
              "      <td>0.683379</td>\n",
              "      <td>0.178425</td>\n",
              "      <td>0.440153</td>\n",
              "      <td>0.307709</td>\n",
              "      <td>0.347402</td>\n",
              "      <td>0.600737</td>\n",
              "      <td>0.417914</td>\n",
              "      <td>0.349684</td>\n",
              "      <td>0.321785</td>\n",
              "      <td>0.531979</td>\n",
              "      <td>0.624186</td>\n",
              "      <td>0.368915</td>\n",
              "      <td>0.634003</td>\n",
              "      <td>0.556109</td>\n",
              "      <td>0.558545</td>\n",
              "      <td>0.518952</td>\n",
              "      <td>0.403960</td>\n",
              "      <td>0.396819</td>\n",
              "      <td>0.364760</td>\n",
              "      <td>0.676907</td>\n",
              "      <td>0.685818</td>\n",
              "      <td>0.690572</td>\n",
              "      <td>0.509173</td>\n",
              "      <td>0.525310</td>\n",
              "      <td>0.323403</td>\n",
              "      <td>0.533995</td>\n",
              "      <td>0.455737</td>\n",
              "      <td>0.582377</td>\n",
              "      <td>0.328311</td>\n",
              "      <td>0.709462</td>\n",
              "      <td>0.453018</td>\n",
              "      <td>0.468204</td>\n",
              "      <td>0.567621</td>\n",
              "      <td>0.467874</td>\n",
              "      <td>0.405071</td>\n",
              "      <td>0.582057</td>\n",
              "      <td>0.594016</td>\n",
              "      <td>0.401637</td>\n",
              "      <td>...</td>\n",
              "      <td>0.495832</td>\n",
              "      <td>0.352025</td>\n",
              "      <td>0.480867</td>\n",
              "      <td>0.505033</td>\n",
              "      <td>0.627198</td>\n",
              "      <td>0.295467</td>\n",
              "      <td>0.342243</td>\n",
              "      <td>0.456224</td>\n",
              "      <td>0.404117</td>\n",
              "      <td>0.612571</td>\n",
              "      <td>0.490503</td>\n",
              "      <td>0.586602</td>\n",
              "      <td>0.757448</td>\n",
              "      <td>0.561995</td>\n",
              "      <td>0.578459</td>\n",
              "      <td>0.590630</td>\n",
              "      <td>0.690252</td>\n",
              "      <td>0.448668</td>\n",
              "      <td>0.506996</td>\n",
              "      <td>0.485636</td>\n",
              "      <td>0.245893</td>\n",
              "      <td>0.604970</td>\n",
              "      <td>0.253019</td>\n",
              "      <td>0.600732</td>\n",
              "      <td>0.492193</td>\n",
              "      <td>0.638138</td>\n",
              "      <td>0.386316</td>\n",
              "      <td>0.477193</td>\n",
              "      <td>0.565459</td>\n",
              "      <td>0.366887</td>\n",
              "      <td>0.474382</td>\n",
              "      <td>0.344164</td>\n",
              "      <td>0.544211</td>\n",
              "      <td>0.503846</td>\n",
              "      <td>0.565422</td>\n",
              "      <td>0.410185</td>\n",
              "      <td>0.475016</td>\n",
              "      <td>0.406889</td>\n",
              "      <td>0.460910</td>\n",
              "      <td>0.506161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93480</th>\n",
              "      <td>0.745032</td>\n",
              "      <td>0.230731</td>\n",
              "      <td>0.378909</td>\n",
              "      <td>0.694667</td>\n",
              "      <td>0.284413</td>\n",
              "      <td>0.614541</td>\n",
              "      <td>0.396604</td>\n",
              "      <td>0.364991</td>\n",
              "      <td>0.446703</td>\n",
              "      <td>0.461701</td>\n",
              "      <td>0.388680</td>\n",
              "      <td>0.393004</td>\n",
              "      <td>0.449561</td>\n",
              "      <td>0.604696</td>\n",
              "      <td>0.373478</td>\n",
              "      <td>0.424800</td>\n",
              "      <td>0.465199</td>\n",
              "      <td>0.427342</td>\n",
              "      <td>0.320420</td>\n",
              "      <td>0.431498</td>\n",
              "      <td>0.581815</td>\n",
              "      <td>0.416632</td>\n",
              "      <td>0.350087</td>\n",
              "      <td>0.549052</td>\n",
              "      <td>0.577194</td>\n",
              "      <td>0.464202</td>\n",
              "      <td>0.589057</td>\n",
              "      <td>0.458569</td>\n",
              "      <td>0.441014</td>\n",
              "      <td>0.458100</td>\n",
              "      <td>0.419587</td>\n",
              "      <td>0.418288</td>\n",
              "      <td>0.505176</td>\n",
              "      <td>0.454045</td>\n",
              "      <td>0.507588</td>\n",
              "      <td>0.428591</td>\n",
              "      <td>0.633479</td>\n",
              "      <td>0.567558</td>\n",
              "      <td>0.437403</td>\n",
              "      <td>0.506312</td>\n",
              "      <td>...</td>\n",
              "      <td>0.543967</td>\n",
              "      <td>0.536569</td>\n",
              "      <td>0.521602</td>\n",
              "      <td>0.461931</td>\n",
              "      <td>0.513260</td>\n",
              "      <td>0.294707</td>\n",
              "      <td>0.439343</td>\n",
              "      <td>0.428593</td>\n",
              "      <td>0.409871</td>\n",
              "      <td>0.472767</td>\n",
              "      <td>0.477995</td>\n",
              "      <td>0.548314</td>\n",
              "      <td>0.358082</td>\n",
              "      <td>0.445212</td>\n",
              "      <td>0.404650</td>\n",
              "      <td>0.395949</td>\n",
              "      <td>0.534047</td>\n",
              "      <td>0.429247</td>\n",
              "      <td>0.495555</td>\n",
              "      <td>0.532092</td>\n",
              "      <td>0.511256</td>\n",
              "      <td>0.560836</td>\n",
              "      <td>0.354756</td>\n",
              "      <td>0.538538</td>\n",
              "      <td>0.436488</td>\n",
              "      <td>0.397807</td>\n",
              "      <td>0.467128</td>\n",
              "      <td>0.475108</td>\n",
              "      <td>0.558045</td>\n",
              "      <td>0.435218</td>\n",
              "      <td>0.545864</td>\n",
              "      <td>0.475397</td>\n",
              "      <td>0.364380</td>\n",
              "      <td>0.501192</td>\n",
              "      <td>0.500615</td>\n",
              "      <td>0.390426</td>\n",
              "      <td>0.373361</td>\n",
              "      <td>0.406239</td>\n",
              "      <td>0.477701</td>\n",
              "      <td>0.466176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36090</th>\n",
              "      <td>0.351416</td>\n",
              "      <td>0.398533</td>\n",
              "      <td>0.442142</td>\n",
              "      <td>0.690568</td>\n",
              "      <td>0.184369</td>\n",
              "      <td>0.298014</td>\n",
              "      <td>0.415673</td>\n",
              "      <td>0.121423</td>\n",
              "      <td>0.535906</td>\n",
              "      <td>0.426396</td>\n",
              "      <td>0.561682</td>\n",
              "      <td>0.583194</td>\n",
              "      <td>0.290226</td>\n",
              "      <td>0.520105</td>\n",
              "      <td>0.488883</td>\n",
              "      <td>0.469922</td>\n",
              "      <td>0.485970</td>\n",
              "      <td>0.501893</td>\n",
              "      <td>0.403154</td>\n",
              "      <td>0.521073</td>\n",
              "      <td>0.427183</td>\n",
              "      <td>0.406537</td>\n",
              "      <td>0.429126</td>\n",
              "      <td>0.537421</td>\n",
              "      <td>0.583453</td>\n",
              "      <td>0.417209</td>\n",
              "      <td>0.469267</td>\n",
              "      <td>0.479623</td>\n",
              "      <td>0.438354</td>\n",
              "      <td>0.641176</td>\n",
              "      <td>0.431024</td>\n",
              "      <td>0.414878</td>\n",
              "      <td>0.428524</td>\n",
              "      <td>0.388172</td>\n",
              "      <td>0.352017</td>\n",
              "      <td>0.454651</td>\n",
              "      <td>0.510446</td>\n",
              "      <td>0.527736</td>\n",
              "      <td>0.471925</td>\n",
              "      <td>0.420008</td>\n",
              "      <td>...</td>\n",
              "      <td>0.651573</td>\n",
              "      <td>0.561193</td>\n",
              "      <td>0.575917</td>\n",
              "      <td>0.586932</td>\n",
              "      <td>0.516408</td>\n",
              "      <td>0.556890</td>\n",
              "      <td>0.509615</td>\n",
              "      <td>0.458479</td>\n",
              "      <td>0.302740</td>\n",
              "      <td>0.471902</td>\n",
              "      <td>0.524216</td>\n",
              "      <td>0.455466</td>\n",
              "      <td>0.395405</td>\n",
              "      <td>0.556850</td>\n",
              "      <td>0.514479</td>\n",
              "      <td>0.574461</td>\n",
              "      <td>0.417776</td>\n",
              "      <td>0.570966</td>\n",
              "      <td>0.594238</td>\n",
              "      <td>0.415074</td>\n",
              "      <td>0.538257</td>\n",
              "      <td>0.399470</td>\n",
              "      <td>0.413607</td>\n",
              "      <td>0.467161</td>\n",
              "      <td>0.546672</td>\n",
              "      <td>0.519561</td>\n",
              "      <td>0.318174</td>\n",
              "      <td>0.425171</td>\n",
              "      <td>0.519279</td>\n",
              "      <td>0.458171</td>\n",
              "      <td>0.535411</td>\n",
              "      <td>0.416212</td>\n",
              "      <td>0.444944</td>\n",
              "      <td>0.458182</td>\n",
              "      <td>0.381142</td>\n",
              "      <td>0.340932</td>\n",
              "      <td>0.456118</td>\n",
              "      <td>0.506015</td>\n",
              "      <td>0.539696</td>\n",
              "      <td>0.528282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51343</th>\n",
              "      <td>0.325416</td>\n",
              "      <td>0.427388</td>\n",
              "      <td>0.400724</td>\n",
              "      <td>0.504987</td>\n",
              "      <td>0.328114</td>\n",
              "      <td>0.311179</td>\n",
              "      <td>0.499860</td>\n",
              "      <td>0.451637</td>\n",
              "      <td>0.461253</td>\n",
              "      <td>0.587438</td>\n",
              "      <td>0.428425</td>\n",
              "      <td>0.460136</td>\n",
              "      <td>0.424134</td>\n",
              "      <td>0.251986</td>\n",
              "      <td>0.487621</td>\n",
              "      <td>0.461136</td>\n",
              "      <td>0.191300</td>\n",
              "      <td>0.328360</td>\n",
              "      <td>0.533249</td>\n",
              "      <td>0.417310</td>\n",
              "      <td>0.333733</td>\n",
              "      <td>0.463261</td>\n",
              "      <td>0.366562</td>\n",
              "      <td>0.419060</td>\n",
              "      <td>0.569472</td>\n",
              "      <td>0.277808</td>\n",
              "      <td>0.357063</td>\n",
              "      <td>0.420686</td>\n",
              "      <td>0.335941</td>\n",
              "      <td>0.498247</td>\n",
              "      <td>0.615899</td>\n",
              "      <td>0.505014</td>\n",
              "      <td>0.534454</td>\n",
              "      <td>0.452973</td>\n",
              "      <td>0.397174</td>\n",
              "      <td>0.457927</td>\n",
              "      <td>0.542818</td>\n",
              "      <td>0.443587</td>\n",
              "      <td>0.466924</td>\n",
              "      <td>0.476299</td>\n",
              "      <td>...</td>\n",
              "      <td>0.454045</td>\n",
              "      <td>0.651454</td>\n",
              "      <td>0.434583</td>\n",
              "      <td>0.381887</td>\n",
              "      <td>0.430555</td>\n",
              "      <td>0.458940</td>\n",
              "      <td>0.382573</td>\n",
              "      <td>0.472431</td>\n",
              "      <td>0.503115</td>\n",
              "      <td>0.401045</td>\n",
              "      <td>0.513281</td>\n",
              "      <td>0.319553</td>\n",
              "      <td>0.454184</td>\n",
              "      <td>0.462265</td>\n",
              "      <td>0.518481</td>\n",
              "      <td>0.451960</td>\n",
              "      <td>0.502049</td>\n",
              "      <td>0.524382</td>\n",
              "      <td>0.526280</td>\n",
              "      <td>0.483462</td>\n",
              "      <td>0.407611</td>\n",
              "      <td>0.536615</td>\n",
              "      <td>0.346263</td>\n",
              "      <td>0.456003</td>\n",
              "      <td>0.434085</td>\n",
              "      <td>0.452531</td>\n",
              "      <td>0.455869</td>\n",
              "      <td>0.518795</td>\n",
              "      <td>0.599121</td>\n",
              "      <td>0.508966</td>\n",
              "      <td>0.421911</td>\n",
              "      <td>0.442800</td>\n",
              "      <td>0.490921</td>\n",
              "      <td>0.301930</td>\n",
              "      <td>0.495337</td>\n",
              "      <td>0.480007</td>\n",
              "      <td>0.390370</td>\n",
              "      <td>0.489753</td>\n",
              "      <td>0.528702</td>\n",
              "      <td>0.474643</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 200 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2    ...       197       198       199\n",
              "53032   0.265250  0.452413  0.506515  ...  0.525188  0.502132  0.434729\n",
              "103777  0.527883  0.309239  0.683379  ...  0.406889  0.460910  0.506161\n",
              "93480   0.745032  0.230731  0.378909  ...  0.406239  0.477701  0.466176\n",
              "36090   0.351416  0.398533  0.442142  ...  0.506015  0.539696  0.528282\n",
              "51343   0.325416  0.427388  0.400724  ...  0.489753  0.528702  0.474643\n",
              "\n",
              "[5 rows x 200 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAeW_T5FZbig",
        "outputId": "b6f70e82-5d30-4aa8-d27b-f7f31ad49944"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85442, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvHeqcG8La6r"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ERT01W0pKu2"
      },
      "source": [
        "x_train = np.array(X_train)\n",
        "x_train = np.reshape(x_train, (x_train.shape[0],1, x_train.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cEK8V_boVH7"
      },
      "source": [
        "x_test = np.array(X_test)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0],1, x_test.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raqKeG93Gf9T",
        "outputId": "b01a6ae3-d504-4bf1-ea52-342d4118418e"
      },
      "source": [
        "model_LSTM = Sequential()\n",
        "model_LSTM.add(LSTM(1028, input_shape=(x_train.shape[1],200),return_sequences=True, recurrent_activation='relu'))\n",
        "model_LSTM.add(Dense(800,activation='relu'))\n",
        "#model.add(LSTM(904,return_sequences=False,recurrent_activation='relu'))\n",
        "model_LSTM.add(Dense(3, activation='softmax'))\n",
        "model_LSTM.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 1, 1028)           5053648   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1, 800)            823200    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1, 3)              2403      \n",
            "=================================================================\n",
            "Total params: 5,879,251\n",
            "Trainable params: 5,879,251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0Gpt010GvxN"
      },
      "source": [
        "import keras\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001, amsgrad=True)\n",
        "model_LSTM.compile(loss= loss_fn, optimizer=opt, metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw7_bCr1HTXy",
        "outputId": "b137fc31-411d-459c-f836-9219c4c988f7"
      },
      "source": [
        "model_LSTM.fit(x_train,y_train, batch_size=128, epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "668/668 [==============================] - 9s 8ms/step - loss: 1.0958 - accuracy: 0.3541\n",
            "Epoch 2/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 1.0587 - accuracy: 0.4352\n",
            "Epoch 3/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 1.0240 - accuracy: 0.4763\n",
            "Epoch 4/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.9971 - accuracy: 0.4986\n",
            "Epoch 5/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.9704 - accuracy: 0.5200\n",
            "Epoch 6/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.9411 - accuracy: 0.5400\n",
            "Epoch 7/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.9098 - accuracy: 0.5639\n",
            "Epoch 8/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.8832 - accuracy: 0.5846\n",
            "Epoch 9/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.8582 - accuracy: 0.6054\n",
            "Epoch 10/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.8413 - accuracy: 0.6129\n",
            "Epoch 11/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.8151 - accuracy: 0.6336\n",
            "Epoch 12/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.7855 - accuracy: 0.6497\n",
            "Epoch 13/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.7653 - accuracy: 0.6635\n",
            "Epoch 14/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.7437 - accuracy: 0.6780\n",
            "Epoch 15/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.7105 - accuracy: 0.6954\n",
            "Epoch 16/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.6911 - accuracy: 0.7062\n",
            "Epoch 17/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.6716 - accuracy: 0.7199\n",
            "Epoch 18/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.6461 - accuracy: 0.7318\n",
            "Epoch 19/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.6227 - accuracy: 0.7428\n",
            "Epoch 20/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.6065 - accuracy: 0.7499\n",
            "Epoch 21/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.5873 - accuracy: 0.7605\n",
            "Epoch 22/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.5737 - accuracy: 0.7683\n",
            "Epoch 23/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.5505 - accuracy: 0.7791\n",
            "Epoch 24/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.5359 - accuracy: 0.7823\n",
            "Epoch 25/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.5244 - accuracy: 0.7871\n",
            "Epoch 26/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.5021 - accuracy: 0.8009\n",
            "Epoch 27/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.4866 - accuracy: 0.8065\n",
            "Epoch 28/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.4688 - accuracy: 0.8167\n",
            "Epoch 29/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.4623 - accuracy: 0.8159\n",
            "Epoch 30/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.4479 - accuracy: 0.8258\n",
            "Epoch 31/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.4272 - accuracy: 0.8323\n",
            "Epoch 32/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.4109 - accuracy: 0.8406\n",
            "Epoch 33/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.3977 - accuracy: 0.8480\n",
            "Epoch 34/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.3866 - accuracy: 0.8515\n",
            "Epoch 35/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.3756 - accuracy: 0.8564\n",
            "Epoch 36/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.3604 - accuracy: 0.8607\n",
            "Epoch 37/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.3604 - accuracy: 0.8626\n",
            "Epoch 38/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.3393 - accuracy: 0.8702\n",
            "Epoch 39/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.3336 - accuracy: 0.8746\n",
            "Epoch 40/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.3190 - accuracy: 0.8805\n",
            "Epoch 41/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.3122 - accuracy: 0.8828\n",
            "Epoch 42/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.3065 - accuracy: 0.8842\n",
            "Epoch 43/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.2940 - accuracy: 0.8913\n",
            "Epoch 44/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.2803 - accuracy: 0.8956\n",
            "Epoch 45/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.2830 - accuracy: 0.8940\n",
            "Epoch 46/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.2834 - accuracy: 0.8935\n",
            "Epoch 47/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.2655 - accuracy: 0.9012\n",
            "Epoch 48/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.2598 - accuracy: 0.9026\n",
            "Epoch 49/50\n",
            "668/668 [==============================] - 5s 7ms/step - loss: 0.2479 - accuracy: 0.9072\n",
            "Epoch 50/50\n",
            "668/668 [==============================] - 5s 8ms/step - loss: 0.2460 - accuracy: 0.9097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f63a01e7110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7Q-hsKXWMal"
      },
      "source": [
        "pred_lstm = model_LSTM.predict_classes(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ-7IRALWgQ8",
        "outputId": "cf6c8669-d177-49c2-9c2f-e08cd7823a6b"
      },
      "source": [
        "print('Accuracy score of the model:')\n",
        "print(accuracy_score(y_test, pred_lstm))\n",
        "print(\"Confusion matrix of the model:\")\n",
        "print(confusion_matrix(y_test, pred_lstm))\n",
        "print(\"Classification report the model:\")\n",
        "print(classification_report(y_test, pred_lstm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score of the model:\n",
            "0.8648939656383128\n",
            "Confusion matrix of the model:\n",
            "[[6441  191  496]\n",
            " [ 183 6240  618]\n",
            " [ 633  765 5794]]\n",
            "Classification report the model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.90      0.90      7128\n",
            "           1       0.87      0.89      0.88      7041\n",
            "           2       0.84      0.81      0.82      7192\n",
            "\n",
            "    accuracy                           0.86     21361\n",
            "   macro avg       0.86      0.87      0.86     21361\n",
            "weighted avg       0.86      0.86      0.86     21361\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ldPR0ki8Rol"
      },
      "source": [
        "lstm_model = '/content/drive/MyDrive/BERT + STOCK /Fine-tuned Models/lstm.sav'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BHGR9UH8ZAd"
      },
      "source": [
        "pickle.dump(lstm_model, open(lstm_model, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69kAQYMP-lTg",
        "outputId": "c0e46175-21e0-4889-ec17-7c714fd7704d"
      },
      "source": [
        "lstm_model_json = model_LSTM.to_json()\n",
        "with open(\"/content/drive/MyDrive/BERT + STOCK /Fine-tuned Models/model_LSTM.json\", \"w\") as json_file:\n",
        "    json_file.write(lstm_model_json)\n",
        "# serialize weights to HDF5\n",
        "model_LSTM.save_weights(\"/content/drive/MyDrive/BERT + STOCK /Fine-tuned Models/model_LSTM.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_PaF2XkLa35",
        "outputId": "89405342-6854-4f28-8719-3f1636404e14"
      },
      "source": [
        "model_mlp = Sequential()\n",
        "#model.add(LSTM(1028, input_shape=(x_train.shape[1],250),return_sequences=True, recurrent_activation='relu'))\n",
        "#model.add(LSTM(904,return_sequences=False,recurrent_activation='relu'))\n",
        "model_mlp.add(Dense(1028, input_shape=(x_train.shape[1],200), activation='relu'))\n",
        "model_mlp.add(Dropout(0.3))\n",
        "model_mlp.add(Dense(800,activation='relu'))\n",
        "model_mlp.add(Dropout(0.3))\n",
        "model_mlp.add(Dense(400,activation='relu'))\n",
        "model_mlp.add(Dropout(0.3))\n",
        "model_mlp.add(Dense(200,activation='relu'))\n",
        "model_mlp.add(Dropout(0.3))\n",
        "model_mlp.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model_mlp.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 1, 1028)           206628    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1, 1028)           0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1, 800)            823200    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 800)            0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1, 400)            320400    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 400)            0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1, 200)            80200     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1, 200)            0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1, 3)              603       \n",
            "=================================================================\n",
            "Total params: 1,431,031\n",
            "Trainable params: 1,431,031\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10WXCoSsOS0I"
      },
      "source": [
        "import keras\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001, amsgrad=True)\n",
        "import tensorflow as tf\n",
        "metric = tf.keras.metrics.SparseTopKCategoricalAccuracy()\n",
        "model_mlp.compile(loss= loss_fn, optimizer=opt, metrics = ['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AIKjd0vLa1a",
        "outputId": "0ce5bfd3-f407-413d-981f-f4a1dbbdd254"
      },
      "source": [
        "model_mlp.fit(x_train,y_train, batch_size=128, epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "668/668 [==============================] - 4s 5ms/step - loss: 1.1035 - accuracy: 0.3429\n",
            "Epoch 2/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 1.0818 - accuracy: 0.3933\n",
            "Epoch 3/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 1.0391 - accuracy: 0.4504\n",
            "Epoch 4/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 1.0046 - accuracy: 0.4854\n",
            "Epoch 5/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.9795 - accuracy: 0.5086\n",
            "Epoch 6/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.9536 - accuracy: 0.5267\n",
            "Epoch 7/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.9346 - accuracy: 0.5424\n",
            "Epoch 8/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.9146 - accuracy: 0.5602\n",
            "Epoch 9/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.8946 - accuracy: 0.5740\n",
            "Epoch 10/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.8697 - accuracy: 0.5933\n",
            "Epoch 11/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.8536 - accuracy: 0.6030\n",
            "Epoch 12/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.8318 - accuracy: 0.6184\n",
            "Epoch 13/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.7914 - accuracy: 0.6475\n",
            "Epoch 14/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.7623 - accuracy: 0.6634\n",
            "Epoch 15/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.7306 - accuracy: 0.6819\n",
            "Epoch 16/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.6910 - accuracy: 0.7054\n",
            "Epoch 17/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.6674 - accuracy: 0.7152\n",
            "Epoch 18/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.6371 - accuracy: 0.7323\n",
            "Epoch 19/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.6109 - accuracy: 0.7458\n",
            "Epoch 20/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.5780 - accuracy: 0.7599\n",
            "Epoch 21/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.5635 - accuracy: 0.7667\n",
            "Epoch 22/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.5470 - accuracy: 0.7744\n",
            "Epoch 23/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.5325 - accuracy: 0.7795\n",
            "Epoch 24/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.5100 - accuracy: 0.7917\n",
            "Epoch 25/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.4946 - accuracy: 0.8005\n",
            "Epoch 26/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.4760 - accuracy: 0.8069\n",
            "Epoch 27/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.4554 - accuracy: 0.8171\n",
            "Epoch 28/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.4451 - accuracy: 0.8199\n",
            "Epoch 29/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.4393 - accuracy: 0.8241\n",
            "Epoch 30/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.4282 - accuracy: 0.8274\n",
            "Epoch 31/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.4140 - accuracy: 0.8350\n",
            "Epoch 32/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.4055 - accuracy: 0.8380\n",
            "Epoch 33/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.4005 - accuracy: 0.8407\n",
            "Epoch 34/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.3785 - accuracy: 0.8498\n",
            "Epoch 35/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.3797 - accuracy: 0.8490\n",
            "Epoch 36/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.3613 - accuracy: 0.8574\n",
            "Epoch 37/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.3571 - accuracy: 0.8603\n",
            "Epoch 38/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.3538 - accuracy: 0.8595\n",
            "Epoch 39/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.3472 - accuracy: 0.8627\n",
            "Epoch 40/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.3336 - accuracy: 0.8683\n",
            "Epoch 41/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.3333 - accuracy: 0.8682\n",
            "Epoch 42/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.3223 - accuracy: 0.8746\n",
            "Epoch 43/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.3173 - accuracy: 0.8740\n",
            "Epoch 44/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.3224 - accuracy: 0.8733\n",
            "Epoch 45/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.3062 - accuracy: 0.8798\n",
            "Epoch 46/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.3052 - accuracy: 0.8822\n",
            "Epoch 47/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.2967 - accuracy: 0.8849\n",
            "Epoch 48/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.2962 - accuracy: 0.8832\n",
            "Epoch 49/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.2889 - accuracy: 0.8879\n",
            "Epoch 50/50\n",
            "668/668 [==============================] - 3s 5ms/step - loss: 0.2937 - accuracy: 0.8859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f635260dc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bg07jpGLanH"
      },
      "source": [
        "model_mlp.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWSFhFJ8LajM"
      },
      "source": [
        "pred_mlp = model_mlp.predict_classes(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbo30_FnLagP",
        "outputId": "fa6718a0-5270-47b1-9ea5-649bab79c81e"
      },
      "source": [
        "print('Accuracy score of the MLP model:')\n",
        "print(accuracy_score(y_test, pred_mlp))\n",
        "print(\"Confusion matrix of the MLP model:\")\n",
        "print(confusion_matrix(y_test, pred_mlp))\n",
        "print(\"Classification report the MLP model:\")\n",
        "print(classification_report(y_test, pred_mlp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score of the MLP model:\n",
            "0.8692945086840503\n",
            "Confusion matrix of the MLP model:\n",
            "[[7058   27   43]\n",
            " [ 138 6791  112]\n",
            " [1457 1015 4720]]\n",
            "Classification report the MLP model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.99      0.89      7128\n",
            "           1       0.87      0.96      0.91      7041\n",
            "           2       0.97      0.66      0.78      7192\n",
            "\n",
            "    accuracy                           0.87     21361\n",
            "   macro avg       0.88      0.87      0.86     21361\n",
            "weighted avg       0.88      0.87      0.86     21361\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIwtMa9y8eqe"
      },
      "source": [
        "mlp_model = '/content/drive/MyDrive/BERT + STOCK /Fine-tuned Models/mlp.sav'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_siuhX_q8emr"
      },
      "source": [
        "pickle.dump(mlp_model, open(mlp_model, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4c_m5teAiaP",
        "outputId": "800aca61-7f70-44e4-ff56-60ce189116b6"
      },
      "source": [
        "mlp_model_json = model_mlp.to_json()\n",
        "with open(\"/content/drive/MyDrive/BERT + STOCK /Fine-tuned Models/model_MLP.json\", \"w\") as json_file:\n",
        "    json_file.write(mlp_model_json)\n",
        "# serialize weights to HDF5\n",
        "model_mlp.save_weights(\"/content/drive/MyDrive/BERT + STOCK /Fine-tuned Models/model_MLP.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wal747eS7Gws"
      },
      "source": [
        "xg_model_basic = XGBClassifier(tree_method='gpu_hist' ).fit(X_train, y_train)\n",
        "preds = xg_model_basic.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYO5YuUL7OmY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1250f5c-33d6-4e14-9624-63c275d6927e"
      },
      "source": [
        "print('Accuracy score of the model:')\n",
        "print(accuracy_score(y_test, preds))\n",
        "print(\"Confusion matrix of the model:\")\n",
        "print(confusion_matrix(y_test, preds))\n",
        "print(\"Classification report the model:\")\n",
        "print(classification_report(y_test, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score of the model:\n",
            "0.5768456532933851\n",
            "Confusion matrix of the model:\n",
            "[[4060 1697 1371]\n",
            " [1636 4009 1396]\n",
            " [1375 1564 4253]]\n",
            "Classification report the model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.57      0.57      7128\n",
            "           1       0.55      0.57      0.56      7041\n",
            "           2       0.61      0.59      0.60      7192\n",
            "\n",
            "    accuracy                           0.58     21361\n",
            "   macro avg       0.58      0.58      0.58     21361\n",
            "weighted avg       0.58      0.58      0.58     21361\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MUIFRxg0OLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd1b350-deb1-494a-9a37-c7226954338f"
      },
      "source": [
        "#param_grid = dict(max_depth=max_depth)\n",
        "model = XGBClassifier(tree_method='gpu_hist')\n",
        "param_grid = {\n",
        "        'min_child_weight': [1, 5, 10],\n",
        "        'colsample_bytree': [0.6, 0.8],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'learning_rate': [0.01, 0.02]\n",
        "        }\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
        "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold, verbose=1)\n",
        "grid_result = grid_search.fit(X_scaled, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 25.0min\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed: 66.3min\n",
            "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 80.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: -0.848159 using {'colsample_bytree': 0.8, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-16qR8ppZse"
      },
      "source": [
        "xg_model=XGBClassifier(colsample_bytree=1.0, learning_rate =0.05, max_depth= 10, min_child_weight=1,tree_method='gpu_hist' ).fit(X_train, y_train)\n",
        "preds = xg_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpBfFvDzqUwu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3926d5ef-8214-4112-c39c-173d0f9836c4"
      },
      "source": [
        "print('Accuracy score of the model:')\n",
        "print(accuracy_score(y_test, preds))\n",
        "print(\"Confusion matrix of the model:\")\n",
        "print(confusion_matrix(y_test, preds))\n",
        "print(\"Classification report the model:\")\n",
        "print(classification_report(y_test, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score of the model:\n",
            "0.8875988951828098\n",
            "Confusion matrix of the model:\n",
            "[[6711  226  191]\n",
            " [ 291 6501  249]\n",
            " [ 721  723 5748]]\n",
            "Classification report the model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.90      7128\n",
            "           1       0.87      0.92      0.90      7041\n",
            "           2       0.93      0.80      0.86      7192\n",
            "\n",
            "    accuracy                           0.89     21361\n",
            "   macro avg       0.89      0.89      0.89     21361\n",
            "weighted avg       0.89      0.89      0.89     21361\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nRRDmemqrrX"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KwziR_yquP9"
      },
      "source": [
        "xgboost_model = '/content/drive/MyDrive/BERT + STOCK /Fine-tuned Models/xgboost.sav'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbIepo8Oq2_E"
      },
      "source": [
        "pickle.dump(xg_model, open(xgboost_model, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}